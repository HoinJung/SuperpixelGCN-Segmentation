{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df3db378-a42f-4f77-bbd9-bdd9c30f54b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import dgl\n",
    "from GraphSage import GraphSageNet, GraphSageNet_sampler ,GraphMultiNet, GNN\n",
    "import time\n",
    "import os\n",
    "import wandb\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "import yaml\n",
    "import sys\n",
    "sys.path.append('../preprocessing')\n",
    "from UAVidToolKit.colorTransformer import UAVidColorTransformer\n",
    "from mit_semseg.utils import AverageMeter, colorEncode, accuracy, intersectionAndUnion\n",
    "import glob\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from skimage.io import imread\n",
    "import pandas as pd\n",
    "# import sys\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from skimage.segmentation import slic, mark_boundaries\n",
    "from skimage.io import imsave\n",
    "import os\n",
    "import torch\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "\n",
    "\n",
    "class Tester(object):\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        config['device'] = self.device\n",
    "        self.batch_size = config['training']['batch_size']\n",
    "        self.train_id =  config['test']['train_id']\n",
    "        \n",
    "        self.model_path = os.path.join(config['test']['ckpt_dir'] ,'ckpt_'+str(self.train_id),config['test']['ckpt_file'])\n",
    "        self.save_dir = os.path.join(config['test']['save_result_dir']);   os.makedirs(self.save_dir, exist_ok = True)\n",
    "        \n",
    "        self.n_class = config['training']['n_classes']\n",
    "        self.sampler = config['sampler']['sampler_true']\n",
    "        self.sampler_neighbor = config['sampler']['sampler_neighbor']\n",
    "        # self.test_data= data_test_generator(config)\n",
    "        # multi_scale mode\n",
    "        self.multi_scale = config['multi_scale_mode']['use_multi_scale']\n",
    "        if self.sampler : \n",
    "            self.model = GraphSageNet_sampler(config).to(self.device)\n",
    "        elif self.multi_scale : \n",
    "            self.model = GraphMultiNet(config).to(self.device)\n",
    "        # elif config['test_mode']:\n",
    "        #     self.model = GNN(config).to(self.device)\n",
    "        else : \n",
    "            self.model = GraphSageNet(config).to(self.device)\n",
    "        # self.model = torch.nn.DataParallel(self.model)\n",
    "        self.result_name = 'result'+'_'+str(self.train_id)\n",
    "        \n",
    "        \n",
    "    def test(self):\n",
    "        self.model.load_state_dict(torch.load(self.model_path,map_location=self.device),strict=False)\n",
    "        self.model.eval()\n",
    "        torch.cuda.empty_cache()\n",
    "        print('dataloading...')\n",
    "        self.raw_data = pd.read_pickle(os.path.join(self.config['data']['pickle_dir'], self.config['test']['test_pickle_name']))  \n",
    "        with torch.no_grad(): \n",
    "            \n",
    "            \n",
    "            print('Test...')\n",
    "            test_acc = []\n",
    "            save_test_result = []\n",
    "            \n",
    "            for idx, row in tqdm(self.raw_data.iterrows()):\n",
    "                spixel= row['superpixel_segment']\n",
    "                gt_path = row['gt_path']\n",
    "                G = row['G']\n",
    "                feature = row['feature']\n",
    "                feature[:,:3] = feature[:,:3] / 255 # rgb normalization\n",
    "                edges = row['edges']\n",
    "                label_gt = row['label_gt']\n",
    "                num_nodes = len(label_gt)\n",
    "                edges_src = torch.tensor(edges[:,0])\n",
    "                edges_dst = torch.tensor(edges[:,1])\n",
    "                dgel_graph = dgl.graph((edges_src , edges_dst), num_nodes=num_nodes, idtype=torch.int32)\n",
    "                dgel_graph.ndata['feat'] = torch.from_numpy(feature)\n",
    "                dgel_graph.ndata['label'] = torch.from_numpy(np.array(label_gt))\n",
    "                dgel_graph = dgl.add_self_loop(dgel_graph)\n",
    "                \n",
    "                if self.sampler :\n",
    "                    sampler = dgl.dataloading.MultiLayerNeighborSampler(self.sampler_neighbor)\n",
    "                    dataloader = dgl.dataloading.NodeDataLoader(\n",
    "                        dgel_graph, torch.arange(dgel_graph.number_of_nodes()).to(torch.int32), sampler,\n",
    "                        shuffle=True,drop_last=False)\n",
    "                    for input_nodes, output_nodes, blocks in dataloader:\n",
    "                        feature_test  = blocks[0].srcdata['feat'].to(self.device)\n",
    "                        label_test = blocks[-1].dstdata['label'].to(self.device)\n",
    "                        # weight = blocks[-1].dstdata['pixel_num'].to(self.device)\n",
    "                        blocks = [b.to(torch.device(self.device)) for b in blocks]\n",
    "                        output_test = self.model(blocks, feature_test) \n",
    "                        \n",
    "                elif self.multi_scale : \n",
    "                    feature_test  = dgel_graph.ndata['feat'].to(self.device)\n",
    "                    label_test = dgel_graph.ndata['label'].to(self.device)\n",
    "                    G_test = dgel_graph.to(self.device)\n",
    "                    \n",
    "                    \n",
    "                    output_test_1, output_test_2, output_test_3 = self.model(G_test, feature_test)\n",
    "                    output_test = (output_test_1+ output_test_2+ output_test_3) / 3\n",
    "                    \n",
    "                    # output_test_1, output_test_2, output_test_3, output_test_4 = self.model(G_test, feature_test)\n",
    "                    # output_test = (output_test_1+ output_test_2+ output_test_3+output_test_4) / 4\n",
    "                    \n",
    "                    # output_test = output_test_1\n",
    "                else : \n",
    "                    feature_test  = dgel_graph.ndata['feat'].to(self.device)\n",
    "                    label_test = dgel_graph.ndata['label'].to(self.device)\n",
    "                    G_test = dgel_graph.to(self.device)\n",
    "                    output_test = self.model(G_test, feature_test) \n",
    "                label_test_onehot = F.one_hot(label_test.to(torch.int64), self.n_class) \n",
    "                label_test = torch.max(label_test_onehot, 1)[1]\n",
    "    \n",
    "                # calculate accuracy\n",
    "                \n",
    "                pred = output_test.argmax(dim=1, keepdim=True)\n",
    "                 \n",
    "                pred = output_test.argmax(dim=1, keepdim=True)\n",
    "                crr = pred.eq(label_test.view_as(pred)).sum().item()\n",
    "                acc = crr / len(pred)\n",
    "                test_acc.append(acc)\n",
    "                feature_test = feature_test.cpu().numpy()\n",
    "                label_test = label_test.cpu().numpy()\n",
    "                \n",
    "                # output_test = output_test.cpu().numpy()\n",
    "                # label_test = label_test.cpu().numpy()\n",
    "                pred = pred.cpu().numpy()\n",
    "                \n",
    "                # save_test_result.append([spixel, gt_path, feature_test,label_test,G,output_test,label_gt,pred])\n",
    "                save_test_result.append([spixel, gt_path, label_test,pred])\n",
    "            \n",
    "            print(\"validation acc : {:.6f}\".format( np.mean(test_acc) ))\n",
    "            pred = pd.DataFrame(save_test_result)\n",
    "            # df.columns = ['spixel','gt_path','feature_test','label_test','G','output_test','label_gt','pred']\n",
    "            pred.columns = ['spixel','gt_path','label_test','pred']\n",
    "            \n",
    "            print('Save Dataframe...')\n",
    "            pred.to_pickle(os.path.join(self.save_dir,self.result_name + '.pickle'))\n",
    "            \n",
    "            print(\"Start Evaluation....\")\n",
    "            \n",
    "            #### eval part\n",
    "            # num = pred_pickle_path.split('/')[1].split('_')[1].split('.')[0]\n",
    "            save_path = f'convert_test_set/pred_g2i_{self.train_id}/'\n",
    "            os.makedirs(save_path,exist_ok=True)\n",
    "            convert_Graph_to_Image_function(save_path, pred,self.device)\n",
    "            pred_path = save_path\n",
    "            \n",
    "            \n",
    "            return pred_path\n",
    "    \n",
    "def convert_Graph_to_Image_function(save_path, df,device):\n",
    "    \n",
    "    for px in tqdm(range(len(df))):\n",
    "        \n",
    "        row = df.iloc[px]\n",
    "        name_path = row['gt_path']\n",
    "        name = name_path.split('/')\n",
    "        \n",
    "        save_name_pred = save_path + name[4] + '_' + name[-1].split('.')[0]\n",
    "        # print(save_name_pred)\n",
    "        \n",
    "        G2_img = np.zeros((row['spixel'].shape[0], row['spixel'].shape[1]))\n",
    "        \n",
    "\n",
    "        G2_img = torch.from_numpy(G2_img)\n",
    "        G2_img = G2_img.to(torch.device(device))\n",
    "        \n",
    "        prediction_cl = np.array(row['pred'])\n",
    "        test_cl = np.array(row['label_test'])\n",
    "        superpixel_img = np.array(row['spixel'])\n",
    "        \n",
    "        node_num = np.amax(superpixel_img)\n",
    "                           \n",
    "        prediction_cl = torch.from_numpy(prediction_cl)\n",
    "        prediction_cl = prediction_cl.to(torch.device(device))\n",
    "        \n",
    "        test_cl = torch.from_numpy(test_cl)\n",
    "        test_cl = test_cl.to(torch.device(device))\n",
    "    \n",
    "        superpixel_img = torch.from_numpy(superpixel_img)\n",
    "        superpixel_img = superpixel_img.to(torch.device(device))\n",
    "\n",
    "        for ix in range(node_num):\n",
    "            \n",
    "            superpixel_cluster = (superpixel_img[:,:] == ix)\n",
    "            \n",
    "            \n",
    "            prediction_superpixel_cluster_node_mapping = torch.multiply(superpixel_cluster, prediction_cl[ix])\n",
    "            \n",
    "            \n",
    "            \n",
    "            G2_img = torch.add(G2_img, prediction_superpixel_cluster_node_mapping)\n",
    "            \n",
    "        \n",
    "        G2_img = G2_img.cpu().numpy()\n",
    "        \n",
    "        \n",
    "        np.save(save_name_pred, G2_img)\n",
    "        # imsave(save_name_pred, G2_img)\n",
    "        \n",
    "    \n",
    "\n",
    "def parse(path):\n",
    "    with open(path, 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "        f.close()\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379364f3-9a25-49bf-b53f-f1d13fd6e3d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train id : 1639144604, hidden dim : 256, out_dim : 256 , Layers : 10\n",
      "dataloading...\n",
      "Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "70it [00:02, 30.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc : 0.692261\n",
      "Save Dataframe...\n",
      "Start Evaluation....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                           | 57/70 [14:43<03:33, 16.42s/it]"
     ]
    }
   ],
   "source": [
    "now = int(time.time())\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('--config_yaml','-yml', type=str, default='train_hi.yaml')\n",
    "# args = parser.parse_args()\n",
    "config_path = f'yml/train_uav_multi_SY.yaml'\n",
    "# config_path = f'yml/train_uav_test.yaml'\n",
    "# config_path = f'yml/train_uav.yaml'\n",
    "config = parse(config_path)\n",
    "# os.environ['CUDA_VISIBLE_DEVICES']=str(config['training']['gpu']['id'] )    \n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "\n",
    "\n",
    "wandb_name = config['test']['wandb_name']\n",
    "try :\n",
    "    wandb_names = wandb_name.split('_')\n",
    "    config['hidden_dim'] = int(wandb_names[4])\n",
    "    config['out_dim'] = int(wandb_names[5])\n",
    "    config['Layer'] = int(wandb_names[6])\n",
    "    config['test']['train_id'] = wandb_names[-1]\n",
    "    print(f\"train id : {config['test']['train_id']}, hidden dim : {config['hidden_dim']}, out_dim : {config['out_dim']} , Layers : {config['Layer']}\")\n",
    "except : \n",
    "\n",
    "    print(f\"train id : {config['test']['train_id']}\")\n",
    "\n",
    "tester = Tester(config=config)\n",
    "pred_path = tester.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5291af1e-7f70-4355-b58b-3befe8621d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(pred_path,n_class):\n",
    "    pred_list = glob.glob(pred_path+'/*')\n",
    "    count = 0\n",
    "\n",
    "    jaccard_list = []\n",
    "    for ix in tqdm(range(len(pred_list))):\n",
    "        pred_name = pred_list[ix]\n",
    "\n",
    "        \n",
    "        # uavid_patch\n",
    "        # pred_seq = pred_name.split('/')[-1].split('_')[0]\n",
    "        # pred_patch = pred_name.split('/')[-1].split('_')[1]\n",
    "        # pred_num = pred_name.split('/')[-1].split('_')[2]\n",
    "        # gt_path = '../data/uavid/uavid_val_patch(2048)/'+ pred_seq + '/Labels/' + pred_patch+'_'+pred_num\n",
    "        # gt_img = imread(gt_path.replace('npy','png'))\n",
    "        \n",
    "        # uavid_full\n",
    "        pred_seq = pred_name.split('/')[-1].split('_')[0]\n",
    "        pred_num = pred_name.split('/')[-1].split('_')[1]\n",
    "        gt_path = '../data/uavid/uavid_val/'+ pred_seq + '/Labels/' +pred_num\n",
    "        gt_img = imread(gt_path.replace('npy','png'))\n",
    "        clrEnc = UAVidColorTransformer()\n",
    "        gt_img = clrEnc.transform(gt_img, dtype=np.uint8)\n",
    "\n",
    "        #city \n",
    "        # city = pred_name.split('/')[-1].split('_')[1]\n",
    "        # label_name = pred_name.split('/')[-1][4:-4:1]\n",
    "        # gt_img = imread(f'../data/cityscape/gtFine/val/{city}/{label_name}')\n",
    "        # gt_img = np.vectorize(mapping_20.get)(gt_img)\n",
    "\n",
    "        pred = np.load(pred_name)\n",
    "        intersection , union = intersectionAndUnion(pred, gt_img, n_class)\n",
    "        jaccard_list.append(intersection/union)\n",
    "    df = pd.DataFrame(jaccard_list)\n",
    "    # df.columns=['Clutter','Building','Road','Static_Car','Tree','Vegetation','Human','Moving_Car']\n",
    "    print('Saving Dataframe....')\n",
    "    # df.to_csv(f'result_1')\n",
    "    describe=df.describe()\n",
    "    print(\"mIoU : \", describe.mean(axis=1)['mean'] * 100)\n",
    "    print('Done!')\n",
    "    return describe, pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44ba5dd-98ed-40cd-8c7d-61f41bed945a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_id =str(1638019938)\n",
    "# pred_path = f'convert_test_set/pred_g2i_{train_id}_full/'\n",
    "# train_id =str(1638155754)\n",
    "# pred_path = f'convert_test_set/pred_g2i_{train_id}/'\n",
    "\n",
    "describe, pred_list = evaluation(pred_path,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e949aa4-2c63-4dd4-96f3-bb3c2a4e6916",
   "metadata": {},
   "outputs": [],
   "source": [
    "describe.columns=['Clutter','Building','Road','Static_Car','Tree','Vegetation','Human','Moving_Car']\n",
    "describe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845a0c02-d000-463d-b992-fce0274b8819",
   "metadata": {},
   "outputs": [],
   "source": [
    "describe.to_csv(f'csv_result/result_{wandb_name}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f48b16-f418-4630-8e2f-bf6cc2c9c387",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imshow\n",
    "\n",
    "from random import *\n",
    " \n",
    "i = randint(1, len(pred_list)) \n",
    "# i = 247\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "ax0 = fig.add_subplot(1,3,1)\n",
    "ax1 = fig.add_subplot(1,3,2)\n",
    "ax2 = fig.add_subplot(1,3,3)\n",
    "pred_img_path = pred_list[i]\n",
    "\n",
    "clrEnc = UAVidColorTransformer()\n",
    "pred_img = np.load(pred_img_path)\n",
    "\n",
    "# uavid patch\n",
    "# pred_seq = pred_img_path.split('/')[-1].split('_')[0]\n",
    "# pred_patch = pred_img_path.split('/')[-1].split('_')[1]\n",
    "# pred_num = pred_img_path.split('/')[-1].split('_')[2]\n",
    "# gt_path = '../data/uavid/uavid_val_patch(1024)/'+ pred_seq + '/Labels/' + pred_patch+'_'+pred_num\n",
    "# gt_img = imread(gt_path.replace('npy','png'))\n",
    "\n",
    "# uavid full\n",
    "pred_seq = pred_img_path.split('/')[-1].split('_')[0]\n",
    "pred_num = pred_img_path.split('/')[-1].split('_')[1]\n",
    "gt_path = '../data/uavid/uavid_val/'+ pred_seq + '/Labels/' + pred_num\n",
    "gt_img = imread(gt_path.replace('npy','png'))\n",
    "gt_img = clrEnc.transform(gt_img, dtype=np.uint8)\n",
    "\n",
    "\n",
    "\n",
    "intersection , union = intersectionAndUnion(pred_img, gt_img, 8)\n",
    "print(gt_img.shape)\n",
    "gt_img = clrEnc.inverse_transform(gt_img)\n",
    "pred_img = clrEnc.inverse_transform(pred_img)\n",
    "# print(['Clutter','Building','Road','Static_Car','Tree','Vegetation','Human','Moving_Car'])\n",
    "# print('')\n",
    "# print(intersection)\n",
    "# print('')\n",
    "# print(union)\n",
    "# print('')\n",
    "# print(intersection/union)\n",
    "\n",
    "ax1.imshow(gt_img)\n",
    "ax2.imshow(pred_img)\n",
    "img_path = gt_path.replace('Labels','Images').replace('npy','png')\n",
    "img = imread(img_path)\n",
    "ax0.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d956b3b-bb66-449a-897e-700831b85c72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['epoch_032_ckpt.pth',\n",
       " 'epoch_005_ckpt.pth',\n",
       " 'epoch_041_ckpt.pth',\n",
       " 'epoch_018_ckpt.pth',\n",
       " 'epoch_013_ckpt.pth',\n",
       " 'epoch_035_ckpt.pth',\n",
       " 'epoch_006_ckpt.pth',\n",
       " 'epoch_049_ckpt.pth',\n",
       " 'epoch_044_ckpt.pth',\n",
       " 'epoch_002_ckpt.pth',\n",
       " 'epoch_019_ckpt.pth',\n",
       " 'epoch_014_ckpt.pth',\n",
       " 'epoch_015_ckpt.pth',\n",
       " 'epoch_025_ckpt.pth',\n",
       " 'epoch_046_ckpt.pth',\n",
       " 'epoch_036_ckpt.pth',\n",
       " 'epoch_048_ckpt.pth',\n",
       " 'epoch_007_ckpt.pth',\n",
       " 'epoch_024_ckpt.pth',\n",
       " 'epoch_008_ckpt.pth']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir('./checkpoints/ckpt_1639017980')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39cb1425-424f-42f5-8b24-68a295ca9912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Dec 12 00:18:43 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 465.27       Driver Version: 465.27       CUDA Version: 11.3     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:3B:00.0 Off |                  N/A |\n",
      "| 35%   39C    P8    29W / 350W |  14779MiB / 24268MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce ...  Off  | 00000000:5E:00.0 Off |                  N/A |\n",
      "| 43%   52C    P2   139W / 350W |  24223MiB / 24268MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA GeForce ...  Off  | 00000000:B1:00.0 Off |                  N/A |\n",
      "| 39%   52C    P2   139W / 350W |  21733MiB / 24268MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA GeForce ...  Off  | 00000000:D9:00.0 Off |                  N/A |\n",
      "| 33%   31C    P8    37W / 350W |      2MiB / 24268MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32398f5b-475a-4f7b-894c-3805ac467bd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
